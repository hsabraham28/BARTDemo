{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Event Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def read_dataset(path):\n",
    "    \"\"\"Load tsv dataset from CASE 2021 shared task.\"\"\"\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        dataset = []\n",
    "        for line in list(f)[1:]:\n",
    "            id, text, label = line.strip().split(\"\\t\")\n",
    "            item = {\n",
    "                \"id\": id, \"text\": text, \"label\": label\n",
    "            }\n",
    "            dataset.append(item)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Simple Zero-Shot Classifier\n",
    "\n",
    "Our approach in a nutshell:\n",
    "* We use a sentence encoder from `sentence-transformers` to convert both label descriptions and texts to predict into embeddings that live in the same embedding space.\n",
    "* At test time, we embed a new text and compare it to each label embedding via cosine similarity.\n",
    "* We assign the label with the highest similarity to the item.\n",
    "* Optionally, we define a minimum similarity threshold that a label needs to pass. If no label passes this threshold, we assign the \"OTHER\" class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroShotClassifier:\n",
    "    \n",
    "    def __init__(self, model=None, threshold=None, null_label=\"OTHER\"):\n",
    "        self.model = model\n",
    "        self.labels = []\n",
    "        self.label_embeddings = None\n",
    "        self.threshold = threshold\n",
    "        self.null_label = null_label\n",
    "    \n",
    "    def train(self, labels, descriptions):\n",
    "        self.labels = labels\n",
    "        self.label_embeddings = model.encode(descriptions)\n",
    "    \n",
    "    def predict(self, input_texts=None, input_embeddings=None, output_scores=False):\n",
    "        \n",
    "        if input_embeddings is None:\n",
    "            input_embeddings = self.model.encode(input_texts)\n",
    "            \n",
    "        S = util.pytorch_cos_sim(input_embeddings, self.label_embeddings)\n",
    "        \n",
    "        predicted_labels = []\n",
    "        predicted_scores = []\n",
    "        for i in range(input_embeddings.shape[0]):\n",
    "            label_scores = S[i].tolist()\n",
    "            scored = sorted(\n",
    "                zip(self.labels, label_scores),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )\n",
    "            pred, score = scored[0]\n",
    "            if self.threshold is not None and score < self.threshold:\n",
    "                pred = self.null_label\n",
    "                \n",
    "            predicted_scores.append(scored)\n",
    "            predicted_labels.append(pred)        \n",
    "        \n",
    "        if output_scores:\n",
    "            return predicted_labels, predicted_scores\n",
    "        else:\n",
    "            return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define your sentence transformer model using CLS pooling\n",
    "model_name = 'bert-base-uncased'\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "# Define a list with sentences (1k - 100k sentences)\n",
    "train_sentences = [\"Your set of sentences\",\n",
    "                   \"Model will automatically add the noise\", \n",
    "                   \"And re-construct it\",\n",
    "                   \"You should provide at least 1k sentences\"]\n",
    "\n",
    "# Create the special denoising dataset that adds noise on-the-fly\n",
    "train_dataset = datasets.DenoisingAutoEncoderDataset(train_sentences)\n",
    "\n",
    "# DataLoader to batch your data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Use the denoising auto-encoder loss\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(model, decoder_name_or_path=model_name, tie_encoder_decoder=True)\n",
    "\n",
    "# Call the fit method\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    weight_decay=0,\n",
    "    scheduler='constantlr',\n",
    "    optimizer_params={'lr': 3e-5},\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "model.save('output/tsdae-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" # set as \"cuda\" instead if you have a GPU set up\n",
    "# the first time this line runs the model will be downloaded \n",
    "model = SentenceTransformer(\"paraphrase-mpnet-base-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_classifier = ZeroShotClassifier(model=model)\n",
    "zs_classifier.train(labels=label_names, descriptions=label_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Building your own Zero-Shot Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build a custom zero-shot classifier in a few lines of code!\n",
    "\n",
    "Let's say we're interested in a small number of natural disasters mentioned in news headlines: earthquakes, wildfires and floods. <br>\n",
    "We want our classifier to detect and classify these and label everything else as \"OTHER\".\n",
    "\n",
    "To do this, we set our classifier up with embeddings of very simple label descriptions (\"earthquake\", \"wildfire\", \"floods\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier = ZeroShotClassifier(\n",
    "    model=model,\n",
    "    threshold=0.3,    \n",
    "    null_label=\"OTHER\"\n",
    ")\n",
    "\n",
    "my_classifier.train(\n",
    "    labels=[\"EARTHQUAKE\", \"WILDFIRE\", \"FLOODS\"],\n",
    "    descriptions=[\"earthquake\", \"wildfire\", \"floods\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the classifier to some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLOODS', 'WILDFIRE', 'EARTHQUAKE', 'OTHER', 'OTHER']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier.predict([\n",
    "    \"Death toll from Hurricane Ida floods rises to 65 in US\",\n",
    "    \"As California burns, some ecologists say it’s time to rethink forest management\",\n",
    "    \"Maharashtra: Tremor in Kolhapur, no casualty\",\n",
    "    \"Leaked Guntrader firearms data file shared. Worst case scenario?\",\n",
    "    \"Taliban take control of last holdout in Panjshir Valley\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results look good!\n",
    "\n",
    "The test examples for `WILDFIRE` and `EARTHQUAKE` above demonstrate that we can correctly classify based on semantic proximity rather than literal word match.\n",
    "\n",
    "This is not going to work perfectly in all cases! But it's a good start for 1 minute of effort. To improve this approach you can tweak the label descriptions and the threshold. \n",
    "\n",
    "You can also use this approach to mine examples for each class you're interested for later manual verification, to build a dataset of ground-truth examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example with fine-grained event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier = ZeroShotClassifier(\n",
    "    model=model,\n",
    "    threshold=0.2,    \n",
    "    null_label=\"OTHER\"\n",
    ")\n",
    "\n",
    "my_classifier.train(\n",
    "    labels=[\"COMP-ACQUISITION\", \"STAKE-ACQUISITION\"],\n",
    "    descriptions=[\n",
    "        \"Company acquires other company\",\n",
    "        \"Company buys stocks/stake in other company\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAKE-ACQUISITION',\n",
       " 'STAKE-ACQUISITION',\n",
       " 'STAKE-ACQUISITION',\n",
       " 'COMP-ACQUISITION',\n",
       " 'COMP-ACQUISITION',\n",
       " 'COMP-ACQUISITION']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier.predict([\n",
    "    \"Galetech Group buys majority stake in Optinergy\",\n",
    "    \"SoftBank acquires minor stake in Deutsche Telekom in new 'long-term partnership'\",\n",
    "    \"EQT buys stake in Sweden's Storytel, becomes second largest shareholder\",\n",
    "    \"UK’s Digital 9 Infrastructure acquires Verne Global for €269.1M; here’s why\",\n",
    "    \"French technology company Lectra acquires Gemini CAD systems\",\n",
    "    \"Quercus buys Arcadia Books as Bielenberg named publisher\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940</td>\n",
       "      <td>T451 no ATO doors at R30-2, 311.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>T507 A10-1 BPD hold for loud music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957</td>\n",
       "      <td>T371 no ATO doors at M16-1, 311.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>Medic10 and Medic16 checked out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>T507 released ATO. 2 min delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004</td>\n",
       "      <td>T365 no ATO doors at M90-2, 311.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>T369 Y10-2 double dashes.\\r\\nNo call from Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2033</td>\n",
       "      <td>T223 no ATO doors at S20-2, 311.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2052</td>\n",
       "      <td>T445 R10-1 possible medical emergency.TO to ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2055</td>\n",
       "      <td>A99 is at R10 and checking on the patron.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time                                                Log\n",
       "0  1940                   T451 no ATO doors at R30-2, 311.\n",
       "1  1957                 T507 A10-1 BPD hold for loud music\n",
       "2  1957                   T371 no ATO doors at M16-1, 311.\n",
       "3  2000                    Medic10 and Medic16 checked out\n",
       "4  2003                     T507 released ATO. 2 min delay\n",
       "5  2004                   T365 no ATO doors at M90-2, 311.\n",
       "6  2022  T369 Y10-2 double dashes.\\r\\nNo call from Central\n",
       "7  2033                   T223 no ATO doors at S20-2, 311.\n",
       "8  2052  T445 R10-1 possible medical emergency.TO to ch...\n",
       "9  2055          A99 is at R10 and checking on the patron."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('unlabeled.csv')[['Time', 'Log']].head(100)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Log</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940</td>\n",
       "      <td>T451 no ATO doors at R30-2, 311.</td>\n",
       "      <td>Mechanical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>T507 A10-1 BPD hold for loud music</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957</td>\n",
       "      <td>T371 no ATO doors at M16-1, 311.</td>\n",
       "      <td>Mechanical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>Medic10 and Medic16 checked out</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>T507 released ATO. 2 min delay</td>\n",
       "      <td>Delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004</td>\n",
       "      <td>T365 no ATO doors at M90-2, 311.</td>\n",
       "      <td>Mechanical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>T369 Y10-2 double dashes.\\r\\nNo call from Central</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2033</td>\n",
       "      <td>T223 no ATO doors at S20-2, 311.</td>\n",
       "      <td>Mechanical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2052</td>\n",
       "      <td>T445 R10-1 possible medical emergency.TO to ch...</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2055</td>\n",
       "      <td>A99 is at R10 and checking on the patron.</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2059</td>\n",
       "      <td>Power outage in the area of Lafayette, trains ...</td>\n",
       "      <td>Police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2059</td>\n",
       "      <td>T445 released ATO, A99 was able to contact the...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2107</td>\n",
       "      <td>Power and lighting restored at C30. Electricia...</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2150</td>\n",
       "      <td>T239 K10-2 BPD hold for a report of someone ex...</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\r\\n2154</td>\n",
       "      <td>T379 Y10-3 route was up for the train but the ...</td>\n",
       "      <td>Delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2157</td>\n",
       "      <td>T239 released ATO, 8 minute delay. T337 delaye...</td>\n",
       "      <td>Delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2200</td>\n",
       "      <td>C80 unstaffed.</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2200</td>\n",
       "      <td>T227 A10-2 BPD hold for a welfare check.</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2201</td>\n",
       "      <td>T509 no ATO doors at M50-1, 311.</td>\n",
       "      <td>Mechanical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2203</td>\n",
       "      <td>T507 M90-1 no ATO doors, Rule 311.</td>\n",
       "      <td>Mechanical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time                                                Log        Pred\n",
       "0       1940                   T451 no ATO doors at R30-2, 311.  Mechanical\n",
       "1       1957                 T507 A10-1 BPD hold for loud music       OTHER\n",
       "2       1957                   T371 no ATO doors at M16-1, 311.  Mechanical\n",
       "3       2000                    Medic10 and Medic16 checked out     Medical\n",
       "4       2003                     T507 released ATO. 2 min delay      Delays\n",
       "5       2004                   T365 no ATO doors at M90-2, 311.  Mechanical\n",
       "6       2022  T369 Y10-2 double dashes.\\r\\nNo call from Central       OTHER\n",
       "7       2033                   T223 no ATO doors at S20-2, 311.  Mechanical\n",
       "8       2052  T445 R10-1 possible medical emergency.TO to ch...     Medical\n",
       "9       2055          A99 is at R10 and checking on the patron.       OTHER\n",
       "10      2059  Power outage in the area of Lafayette, trains ...      Police\n",
       "11      2059  T445 released ATO, A99 was able to contact the...       OTHER\n",
       "12      2107  Power and lighting restored at C30. Electricia...       OTHER\n",
       "13      2150  T239 K10-2 BPD hold for a report of someone ex...     Medical\n",
       "14  \\r\\n2154  T379 Y10-3 route was up for the train but the ...      Delays\n",
       "15      2157  T239 released ATO, 8 minute delay. T337 delaye...      Delays\n",
       "16      2200                                     C80 unstaffed.       OTHER\n",
       "17      2200           T227 A10-2 BPD hold for a welfare check.       OTHER\n",
       "18      2201                   T509 no ATO doors at M50-1, 311.  Mechanical\n",
       "19      2203                 T507 M90-1 no ATO doors, Rule 311.  Mechanical"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier = ZeroShotClassifier(\n",
    "    model=model,\n",
    "    threshold=0.3,    \n",
    "    null_label=\"OTHER\"\n",
    ")\n",
    "\n",
    "my_classifier.train(\n",
    "    labels=[\"Medical\", \"Police\", 'Delays', 'Mechanical'],\n",
    "    descriptions=[\n",
    "        \"medical emergency or injury\",\n",
    "        \"police activity or disturbances\",\n",
    "        \"delays or late departure\",\n",
    "        \"Doors not working or mechanical failure\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "pred = my_classifier.predict(\n",
    "    df['Log'].tolist()\n",
    ")\n",
    "df['Pred'] = pred\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "When tie_encoder_decoder=True, the decoder_name_or_path will be invalid.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f64c38ccc2b483b9553bebba22c25eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d007b1fbba88466da1af4a5dd7217d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define your sentence transformer model using CLS pooling\n",
    "model_name = 'bert-base-uncased'\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "# Define a list with sentences (1k - 100k sentences)\n",
    "train_sentences = [\"Your set of sentences\",\n",
    "                   \"Model will automatically add the noise\", \n",
    "                   \"And re-construct it\",\n",
    "                   \"You should provide at least 1k sentences\"]\n",
    "\n",
    "# Create the special denoising dataset that adds noise on-the-fly\n",
    "train_dataset = datasets.DenoisingAutoEncoderDataset(train_sentences)\n",
    "\n",
    "# DataLoader to batch your data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Use the denoising auto-encoder loss\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(model, decoder_name_or_path=model_name, tie_encoder_decoder=True)\n",
    "\n",
    "# Call the fit method\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    weight_decay=0,\n",
    "    scheduler='constantlr',\n",
    "    optimizer_params={'lr': 3e-5},\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "model.save('output/tsdae-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "device = \"cpu\" # set as \"cuda\" instead if you have a GPU set up\n",
    "# the first time this line runs the model will be downloaded \n",
    "model = SentenceTransformer(\"output/tsdae-model\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
