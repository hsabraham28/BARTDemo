{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objects as go\n",
    "import base64\n",
    "import plotly.express as px\n",
    "import copy\n",
    "from docx import Document\n",
    "from tensorflow import keras\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as pltp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_logs(df, model):\n",
    "    \n",
    "    class_legend = {\n",
    "    0:\"Misc\",\n",
    "    1:'Other BPD',\n",
    "    2:'Homeless',\n",
    "    3:'Medical',\n",
    "    4:'Patron interference',\n",
    "    5:\"Vehicle failure\",\n",
    "    6:\"Wayside equipment\",\n",
    "    7:\"Software related failures\",\n",
    "    8:\"Human Error\",\n",
    "    9:\"Weather\",\n",
    "    10:\"Info (no error)\",\n",
    "    11:\"Delays\",\n",
    "    12:\"Track obstruction\",\n",
    "    13:\"Schedule maintenance\"\n",
    "    }\n",
    "    \n",
    "    df['Cat_Pred'] = df['Log'].apply(lambda log: np.argmax(model.predict([log]), axis=1)[0])\n",
    "    df['Class_Pred'] = df['Cat_Pred'].apply(lambda code: class_legend[code])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_locations(df):\n",
    "    stationlocs = pd.read_csv(\"assets/BARTLocationPercentages.csv\")\n",
    "    station_list = (stationlocs['Station_Name']).tolist()\n",
    "    s_abbrv = [station[:3] for station in station_list]\n",
    "    testlog = df.head(60)\n",
    "    \n",
    "    def lookfornames(c):\n",
    "        for s in s_abbrv:\n",
    "            if s in c:\n",
    "                return s\n",
    "\n",
    "    stationlocs['Location'] = testlog[\"Log\"].apply(lookfornames)\n",
    "    testlog['Location'] = testlog[\"Log\"].apply(lookfornames)\n",
    "    \n",
    "    justxandy = stationlocs.drop(columns=['Station_Name', 'Rain_Critical', 'Asset_Location'])\n",
    "    merged = testlog.merge(justxandy.set_index('Location'), on='Location')\n",
    "    merged['dupped'] = merged.duplicated(subset=['Log'])\n",
    "    merged = merged[merged.dupped != True]\n",
    "    vizdata = merged.drop(columns=['dupped'])\n",
    "    return vizdata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_doc_to_df(filename):\n",
    "    wordDoc = Document(filename)\n",
    "    dfs = []\n",
    "    for table in wordDoc.tables:\n",
    "        data = [[cell.text for cell in row.cells] for row in table.rows]\n",
    "        dfs.append(pd.DataFrame(data))\n",
    "    #column labels are the values of the first row\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df.columns = df.iloc[0] \n",
    "    df = df[1:]\n",
    "    df = df[pd.to_numeric(df['Time'], errors='coerce').notnull()]\n",
    "    df['Time'] = pd.to_numeric(df[\"Time\"])\n",
    "    df = df[df['Log'].map(len) < 300]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotly geo\n",
    "\n",
    "def geoplotly(df):\n",
    "    df = add_locations(df)\n",
    "    model = keras.models.load_model('occ-log-classification/model')\n",
    "    vizdata = classify_logs(df, model)\n",
    "    maptable = copy.copy(vizdata)\n",
    "    maptable[\"xplot\"] = (1200* (maptable['X_Percentage']/100))\n",
    "    maptable[\"yplot\"] = (1080* (maptable['Y_Percentage']/100))\n",
    "    frametable = maptable[[\"xplot\", \"yplot\"]]\n",
    "    xvals = maptable['xplot']\n",
    "    yvals = maptable['yplot']\n",
    "    \n",
    "    #graph\n",
    "    mapfig = go.Figure()\n",
    "\n",
    "    img_width = 1200\n",
    "    img_height = 1080\n",
    "    mapfig.update_layout(\n",
    "        autosize=False\n",
    "    )\n",
    "\n",
    "    bartimage = base64.b64encode(open(\"assets/BARTtracksmap.png\", 'rb').read())\n",
    "    mapfig.add_layout_image(\n",
    "            dict(\n",
    "                source='data:image/png;base64,{}'.format(bartimage.decode()), #\"./assets/BARTtracksmap.png\",\n",
    "                xref=\"x\",\n",
    "                yref=\"y\",\n",
    "                x=0,\n",
    "                y=0,\n",
    "                sizex=img_width,\n",
    "                sizey=img_height,\n",
    "                #sizing=\"stretch\",\n",
    "                opacity=1,\n",
    "                sizing='contain',\n",
    "                layer=\"below\",xanchor=\"left\", yanchor=\"top\")\n",
    "    )\n",
    "    mapfig.update_xaxes(showgrid=False, range=(0, img_width))\n",
    "    mapfig.update_yaxes(showgrid=False, scaleanchor='x', range=(img_height, 0))\n",
    "\n",
    "    mapfig.add_trace(\n",
    "        go.Scatter(x=maptable[\"xplot\"], y=maptable[\"yplot\"], mode=\"markers\", text=maptable['Log'])\n",
    "    )\n",
    "    \n",
    "    #swimscatter\n",
    "    catvizdata = vizdata.drop(columns=['X_Percentage', 'Y_Percentage'])\n",
    "    refs = np.random.choice(np.arange(len(catvizdata['Location'])), len(catvizdata['Location']), replace=False)\n",
    "    catvizdata['Reference'] = refs\n",
    "    import datetime\n",
    "    timarr = []\n",
    "    for t in catvizdata['Time']:\n",
    "        t = int(t)\n",
    "        temp = datetime.time(t//100, t%100)\n",
    "        timarr.append(temp)\n",
    "    catvizdata['Time'] = timarr\n",
    "    from datetime import time\n",
    "    timeaxis = []\n",
    "    start = datetime.time(5, 0, 0)\n",
    "    end = datetime.time(22, 0, 0)\n",
    "    currhr = 5\n",
    "    currmin = 1\n",
    "    timeaxis.append(start)\n",
    "    for i in range(1020):\n",
    "        nexttime = datetime.time(currhr, currmin, 0)\n",
    "        timeaxis.append(nexttime)\n",
    "        if currmin == 59:\n",
    "            currmin = 0\n",
    "            currhr = currhr + 1\n",
    "        else:\n",
    "            currmin = currmin + 1\n",
    "    catvizdata = catvizdata.sort_values(by=['Time'])\n",
    "    xaxistime = catvizdata['Time']\n",
    "    swimscatter = px.scatter(catvizdata, y=\"Class_Pred\", x='Time', color=\"Class_Pred\", symbol=\"Class_Pred\", hover_data=['Log', 'Location'])\n",
    "    swimscatter.update_traces(marker_size=20)\n",
    "    swimscatter.update_xaxes(categoryorder='category ascending', showgrid=False)\n",
    "    \n",
    "    record = catvizdata[[\"Time\", \"Log\", \"Class_Pred\"]]\n",
    "    \n",
    "   # return mapfig, swimscatter\n",
    "    return html.Div([\n",
    "        dcc.Graph(figure=mapfig),\n",
    "        dcc.Graph(figure=swimscatter),\n",
    "        dash_table.DataTable(\n",
    "            record.to_dict('records'),\n",
    "            [{'name': i, 'id': i} for i in record.columns]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from urllib.parse import quote as urlquote\n",
    "\n",
    "from flask import Flask, send_from_directory\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "\n",
    "UPLOAD_DIRECTORY = \"/project/app_uploaded_files\"\n",
    "\n",
    "if not os.path.exists(UPLOAD_DIRECTORY):\n",
    "    os.makedirs(UPLOAD_DIRECTORY)\n",
    "\n",
    "\n",
    "# Normally, Dash creates its own Flask server internally. By creating our own,\n",
    "# we can create a route for downloading files directly:\n",
    "server = Flask(__name__)\n",
    "app = dash.Dash(server=server)\n",
    "\n",
    "\n",
    "@server.route(\"/download/<path:path>\")\n",
    "def download(path):\n",
    "    \"\"\"Serve a file from the upload directory.\"\"\"\n",
    "    return send_from_directory(UPLOAD_DIRECTORY, path, as_attachment=True)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        html.H1(\"OCC Dashboard\"),\n",
    "        html.H2(\"Upload Logs\"),\n",
    "        dcc.Upload(\n",
    "            id=\"upload-data\",\n",
    "            children=html.Div(\n",
    "                [\"Drag and drop or click to select a file to upload.\"]\n",
    "            ),\n",
    "            style={\n",
    "                \"width\": \"100%\",\n",
    "                \"height\": \"60px\",\n",
    "                \"lineHeight\": \"60px\",\n",
    "                \"borderWidth\": \"1px\",\n",
    "                \"borderStyle\": \"dashed\",\n",
    "                \"borderRadius\": \"5px\",\n",
    "                \"textAlign\": \"center\",\n",
    "                \"margin\": \"10px\",\n",
    "            },\n",
    "            multiple=True,\n",
    "        ),\n",
    "        html.H2(\"Dashboard\"),\n",
    "        html.Ul(id=\"file-list\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "def save_file(name, content):\n",
    "    \"\"\"Decode and store a file uploaded with Plotly Dash.\"\"\"\n",
    "    data = content.encode(\"utf8\").split(b\";base64,\")[1]\n",
    "    with open(os.path.join(UPLOAD_DIRECTORY, name), \"wb\") as fp:\n",
    "        fp.write(base64.decodebytes(data))\n",
    "\n",
    "\n",
    "def uploaded_files():\n",
    "    \"\"\"List the files in the upload directory.\"\"\"\n",
    "    files = []\n",
    "    for filename in os.listdir(UPLOAD_DIRECTORY):\n",
    "        path = os.path.join(UPLOAD_DIRECTORY, filename)\n",
    "        if os.path.isfile(path):\n",
    "            files.append(filename)\n",
    "    return files\n",
    "\n",
    "\n",
    "def file_download_link(filename):\n",
    "    \"\"\"Create a Plotly Dash 'A' element that downloads a file from the app.\"\"\"\n",
    "    location = \"/download/{}\".format(urlquote(filename))\n",
    "    return html.A(filename, href=location)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"file-list\", \"children\"),\n",
    "    [Input(\"upload-data\", \"filename\"), Input(\"upload-data\", \"contents\")],\n",
    ")\n",
    "def update_output(uploaded_filenames, uploaded_file_contents):\n",
    "    \"\"\"Save uploaded files and regenerate the file list.\"\"\"\n",
    "\n",
    "    if uploaded_filenames is not None and uploaded_file_contents is not None:\n",
    "        for name, data in zip(uploaded_filenames, uploaded_file_contents):\n",
    "            save_file(name, data)\n",
    "\n",
    "    files = uploaded_files()\n",
    "    if len(files) == 0:\n",
    "        return [html.Li(\"No files yet!\")]\n",
    "    else:\n",
    "        return [geoplotly(word_doc_to_df(os.path.join(UPLOAD_DIRECTORY, filename))) for filename in files]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
